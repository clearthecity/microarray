{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile \n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ILMN_1651217</th>\n",
       "      <th>ILMN_1651229</th>\n",
       "      <th>ILMN_1651234</th>\n",
       "      <th>ILMN_1651236</th>\n",
       "      <th>ILMN_1651237</th>\n",
       "      <th>ILMN_1651254</th>\n",
       "      <th>ILMN_1651259</th>\n",
       "      <th>ILMN_1651260</th>\n",
       "      <th>ILMN_1651261</th>\n",
       "      <th>ILMN_1651262</th>\n",
       "      <th>...</th>\n",
       "      <th>ILMN_1815885</th>\n",
       "      <th>ILMN_1815908</th>\n",
       "      <th>ILMN_1815923</th>\n",
       "      <th>ILMN_1815924</th>\n",
       "      <th>ILMN_1815933</th>\n",
       "      <th>ILMN_1815937</th>\n",
       "      <th>ILMN_1815938</th>\n",
       "      <th>ILMN_1815941</th>\n",
       "      <th>ILMN_1815951</th>\n",
       "      <th>CELIAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.229567</td>\n",
       "      <td>4.802085</td>\n",
       "      <td>4.145582</td>\n",
       "      <td>4.274502</td>\n",
       "      <td>4.268115</td>\n",
       "      <td>6.853804</td>\n",
       "      <td>4.401350</td>\n",
       "      <td>4.123169</td>\n",
       "      <td>4.639975</td>\n",
       "      <td>7.136778</td>\n",
       "      <td>...</td>\n",
       "      <td>4.376735</td>\n",
       "      <td>4.395501</td>\n",
       "      <td>4.338936</td>\n",
       "      <td>5.198647</td>\n",
       "      <td>4.594269</td>\n",
       "      <td>4.264604</td>\n",
       "      <td>4.256310</td>\n",
       "      <td>4.821757</td>\n",
       "      <td>5.005588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.197183</td>\n",
       "      <td>4.820311</td>\n",
       "      <td>4.171221</td>\n",
       "      <td>4.332524</td>\n",
       "      <td>4.186809</td>\n",
       "      <td>6.663657</td>\n",
       "      <td>4.559615</td>\n",
       "      <td>4.278860</td>\n",
       "      <td>4.994493</td>\n",
       "      <td>6.803521</td>\n",
       "      <td>...</td>\n",
       "      <td>4.732124</td>\n",
       "      <td>4.417266</td>\n",
       "      <td>4.656831</td>\n",
       "      <td>4.615440</td>\n",
       "      <td>4.594269</td>\n",
       "      <td>4.336589</td>\n",
       "      <td>4.317376</td>\n",
       "      <td>4.518347</td>\n",
       "      <td>4.308311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.131493</td>\n",
       "      <td>4.640774</td>\n",
       "      <td>4.075849</td>\n",
       "      <td>4.233316</td>\n",
       "      <td>4.334549</td>\n",
       "      <td>6.694727</td>\n",
       "      <td>4.370504</td>\n",
       "      <td>4.169419</td>\n",
       "      <td>5.093272</td>\n",
       "      <td>6.720391</td>\n",
       "      <td>...</td>\n",
       "      <td>4.292552</td>\n",
       "      <td>4.379864</td>\n",
       "      <td>4.211071</td>\n",
       "      <td>5.530672</td>\n",
       "      <td>4.570808</td>\n",
       "      <td>4.379545</td>\n",
       "      <td>4.241886</td>\n",
       "      <td>4.680351</td>\n",
       "      <td>4.780989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.207410</td>\n",
       "      <td>4.508425</td>\n",
       "      <td>4.100585</td>\n",
       "      <td>4.166837</td>\n",
       "      <td>4.530517</td>\n",
       "      <td>6.506971</td>\n",
       "      <td>4.483179</td>\n",
       "      <td>4.242860</td>\n",
       "      <td>5.138309</td>\n",
       "      <td>6.881151</td>\n",
       "      <td>...</td>\n",
       "      <td>4.371180</td>\n",
       "      <td>4.406084</td>\n",
       "      <td>4.186757</td>\n",
       "      <td>5.358646</td>\n",
       "      <td>4.632107</td>\n",
       "      <td>4.282658</td>\n",
       "      <td>4.237614</td>\n",
       "      <td>4.602680</td>\n",
       "      <td>4.637598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.245230</td>\n",
       "      <td>4.538779</td>\n",
       "      <td>4.040637</td>\n",
       "      <td>4.266853</td>\n",
       "      <td>4.326313</td>\n",
       "      <td>6.774611</td>\n",
       "      <td>4.409940</td>\n",
       "      <td>4.228860</td>\n",
       "      <td>4.948306</td>\n",
       "      <td>6.847382</td>\n",
       "      <td>...</td>\n",
       "      <td>4.345227</td>\n",
       "      <td>4.488653</td>\n",
       "      <td>4.364008</td>\n",
       "      <td>5.605900</td>\n",
       "      <td>4.624200</td>\n",
       "      <td>4.275774</td>\n",
       "      <td>4.251683</td>\n",
       "      <td>4.686359</td>\n",
       "      <td>4.687048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ILMN_1651217  ILMN_1651229  ILMN_1651234  ILMN_1651236  ILMN_1651237  \\\n",
       "0      4.229567      4.802085      4.145582      4.274502      4.268115   \n",
       "1      4.197183      4.820311      4.171221      4.332524      4.186809   \n",
       "2      4.131493      4.640774      4.075849      4.233316      4.334549   \n",
       "3      4.207410      4.508425      4.100585      4.166837      4.530517   \n",
       "4      4.245230      4.538779      4.040637      4.266853      4.326313   \n",
       "\n",
       "   ILMN_1651254  ILMN_1651259  ILMN_1651260  ILMN_1651261  ILMN_1651262  ...  \\\n",
       "0      6.853804      4.401350      4.123169      4.639975      7.136778  ...   \n",
       "1      6.663657      4.559615      4.278860      4.994493      6.803521  ...   \n",
       "2      6.694727      4.370504      4.169419      5.093272      6.720391  ...   \n",
       "3      6.506971      4.483179      4.242860      5.138309      6.881151  ...   \n",
       "4      6.774611      4.409940      4.228860      4.948306      6.847382  ...   \n",
       "\n",
       "   ILMN_1815885  ILMN_1815908  ILMN_1815923  ILMN_1815924  ILMN_1815933  \\\n",
       "0      4.376735      4.395501      4.338936      5.198647      4.594269   \n",
       "1      4.732124      4.417266      4.656831      4.615440      4.594269   \n",
       "2      4.292552      4.379864      4.211071      5.530672      4.570808   \n",
       "3      4.371180      4.406084      4.186757      5.358646      4.632107   \n",
       "4      4.345227      4.488653      4.364008      5.605900      4.624200   \n",
       "\n",
       "   ILMN_1815937  ILMN_1815938  ILMN_1815941  ILMN_1815951  CELIAC  \n",
       "0      4.264604      4.256310      4.821757      5.005588       1  \n",
       "1      4.336589      4.317376      4.518347      4.308311       1  \n",
       "2      4.379545      4.241886      4.680351      4.780989       1  \n",
       "3      4.282658      4.237614      4.602680      4.637598       1  \n",
       "4      4.275774      4.251683      4.686359      4.687048       1  \n",
       "\n",
       "[5 rows x 18982 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_samples.csv')\n",
    "df.drop(columns=['Unnamed: 0', 'name'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = list(df.columns[:-1])\n",
    "inputs = df[input_cols]\n",
    "target = df['CELIAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(inputs, target, stratify=target)\n",
    "# X inputs (genes), Y target (disease state)\n",
    "# default test/train split 75/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine classifier (recommended for high-dimensional data; can work with small sample size)\n",
    "svc = SVC(kernel='linear') # only linear models have coef_ and feature_importance_ attributes\n",
    "svc_rfecv = RFECV(estimator=svc,\n",
    "              step=0.1, # remove x% of  features at each iteration\n",
    "              scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_log = SGDClassifier(loss='log', random_state=0)\n",
    "sgd_hinge = SGDClassifier(loss='hinge', random_state=0) # default\n",
    "\n",
    "sgd_l_rfecv = RFECV(estimator=sgd_log,\n",
    "              step=0.1,\n",
    "              scoring='balanced_accuracy')\n",
    "sgd_h_rfecv = RFECV(estimator=sgd_hinge,\n",
    "              step=0.1,\n",
    "              scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_adam = MLPClassifier(random_state=0)\n",
    "mlp_lb = MLPClassifier(solver='lbfgs',\n",
    "                      random_state=0) # limited memory: recommended for smaller sample size\n",
    "                                        # hidden_layer_sizes: default (100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Decision Tree', tree), \n",
    "          ('Random Forest', forest), \n",
    "          (\"Gaussian Naive Bayes\", gnb), \n",
    "          (\"Gradient Descent (logistic)\", sgd_l_rfecv),\n",
    "          (\"Gradient Descent (hinge)\", sgd_h_rfecv),\n",
    "          (\"Support Vector Machines\", svc_rfecv),\n",
    "          (\"MLP (Adam)\", mlp_adam),\n",
    "          (\"MLP (LBFGS)\", mlp_lb)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.50      0.43         6\n",
      "           1       0.88      0.81      0.85        27\n",
      "\n",
      "    accuracy                           0.76        33\n",
      "   macro avg       0.63      0.66      0.64        33\n",
      "weighted avg       0.79      0.76      0.77        33\n",
      "\n",
      "[[0.09 0.09]\n",
      " [0.15 0.67]]\n",
      "\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.82      1.00      0.90        27\n",
      "\n",
      "    accuracy                           0.82        33\n",
      "   macro avg       0.41      0.50      0.45        33\n",
      "weighted avg       0.67      0.82      0.74        33\n",
      "\n",
      "[[0.   0.18]\n",
      " [0.   0.82]]\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29         6\n",
      "           1       0.84      1.00      0.92        27\n",
      "\n",
      "    accuracy                           0.85        33\n",
      "   macro avg       0.92      0.58      0.60        33\n",
      "weighted avg       0.87      0.85      0.80        33\n",
      "\n",
      "[[0.03 0.15]\n",
      " [0.   0.82]]\n",
      "\n",
      "\n",
      "Gradient Descent (logistic)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71         6\n",
      "           1       0.96      0.89      0.92        27\n",
      "\n",
      "    accuracy                           0.88        33\n",
      "   macro avg       0.79      0.86      0.82        33\n",
      "weighted avg       0.90      0.88      0.89        33\n",
      "\n",
      "[[0.15 0.03]\n",
      " [0.09 0.73]]\n",
      "\n",
      "\n",
      "Gradient Descent (hinge)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.82      1.00      0.90        27\n",
      "\n",
      "    accuracy                           0.82        33\n",
      "   macro avg       0.41      0.50      0.45        33\n",
      "weighted avg       0.67      0.82      0.74        33\n",
      "\n",
      "[[0.   0.18]\n",
      " [0.   0.82]]\n",
      "\n",
      "\n",
      "Support Vector Machines\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.93      0.96      0.95        27\n",
      "\n",
      "    accuracy                           0.91        33\n",
      "   macro avg       0.86      0.81      0.84        33\n",
      "weighted avg       0.91      0.91      0.91        33\n",
      "\n",
      "[[0.12 0.06]\n",
      " [0.03 0.79]]\n",
      "\n",
      "\n",
      "MLP (Adam)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      1.00      0.31         6\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.18        33\n",
      "   macro avg       0.09      0.50      0.15        33\n",
      "weighted avg       0.03      0.18      0.06        33\n",
      "\n",
      "[[0.18 0.  ]\n",
      " [0.82 0.  ]]\n",
      "\n",
      "\n",
      "MLP (LBFGS)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.82      1.00      0.90        27\n",
      "\n",
      "    accuracy                           0.82        33\n",
      "   macro avg       0.41      0.50      0.45        33\n",
      "weighted avg       0.67      0.82      0.74        33\n",
      "\n",
      "[[0.   0.18]\n",
      " [0.   0.82]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# precision = TP / (TP + FP)\n",
    "# recall = TP / (TP + FN)\n",
    "# f1-score: harmonic mean of precision and recall\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    print(classification_report(Y_test, prediction,\n",
    "                               zero_division=0))\n",
    "    print(confusion_matrix(Y_test, prediction, \n",
    "                           labels=model.classes_,\n",
    "                          normalize='all'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before RFECV: random forest performs best\n",
    "# after: gradient descent with hinge & SVC perform best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
