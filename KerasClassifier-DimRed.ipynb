{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection: SelectPercentile or RFE/RFECV (recursive feature elimination)\n",
    "# PCA (combines correlated features)\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ILMN_1651217</th>\n",
       "      <th>ILMN_1651229</th>\n",
       "      <th>ILMN_1651234</th>\n",
       "      <th>ILMN_1651236</th>\n",
       "      <th>ILMN_1651237</th>\n",
       "      <th>ILMN_1651254</th>\n",
       "      <th>ILMN_1651259</th>\n",
       "      <th>ILMN_1651260</th>\n",
       "      <th>ILMN_1651261</th>\n",
       "      <th>ILMN_1651262</th>\n",
       "      <th>...</th>\n",
       "      <th>ILMN_1815885</th>\n",
       "      <th>ILMN_1815908</th>\n",
       "      <th>ILMN_1815923</th>\n",
       "      <th>ILMN_1815924</th>\n",
       "      <th>ILMN_1815933</th>\n",
       "      <th>ILMN_1815937</th>\n",
       "      <th>ILMN_1815938</th>\n",
       "      <th>ILMN_1815941</th>\n",
       "      <th>ILMN_1815951</th>\n",
       "      <th>CELIAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.229567</td>\n",
       "      <td>4.802085</td>\n",
       "      <td>4.145582</td>\n",
       "      <td>4.274502</td>\n",
       "      <td>4.268115</td>\n",
       "      <td>6.853804</td>\n",
       "      <td>4.401350</td>\n",
       "      <td>4.123169</td>\n",
       "      <td>4.639975</td>\n",
       "      <td>7.136778</td>\n",
       "      <td>...</td>\n",
       "      <td>4.376735</td>\n",
       "      <td>4.395501</td>\n",
       "      <td>4.338936</td>\n",
       "      <td>5.198647</td>\n",
       "      <td>4.594269</td>\n",
       "      <td>4.264604</td>\n",
       "      <td>4.256310</td>\n",
       "      <td>4.821757</td>\n",
       "      <td>5.005588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.197183</td>\n",
       "      <td>4.820311</td>\n",
       "      <td>4.171221</td>\n",
       "      <td>4.332524</td>\n",
       "      <td>4.186809</td>\n",
       "      <td>6.663657</td>\n",
       "      <td>4.559615</td>\n",
       "      <td>4.278860</td>\n",
       "      <td>4.994493</td>\n",
       "      <td>6.803521</td>\n",
       "      <td>...</td>\n",
       "      <td>4.732124</td>\n",
       "      <td>4.417266</td>\n",
       "      <td>4.656831</td>\n",
       "      <td>4.615440</td>\n",
       "      <td>4.594269</td>\n",
       "      <td>4.336589</td>\n",
       "      <td>4.317376</td>\n",
       "      <td>4.518347</td>\n",
       "      <td>4.308311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.131493</td>\n",
       "      <td>4.640774</td>\n",
       "      <td>4.075849</td>\n",
       "      <td>4.233316</td>\n",
       "      <td>4.334549</td>\n",
       "      <td>6.694727</td>\n",
       "      <td>4.370504</td>\n",
       "      <td>4.169419</td>\n",
       "      <td>5.093272</td>\n",
       "      <td>6.720391</td>\n",
       "      <td>...</td>\n",
       "      <td>4.292552</td>\n",
       "      <td>4.379864</td>\n",
       "      <td>4.211071</td>\n",
       "      <td>5.530672</td>\n",
       "      <td>4.570808</td>\n",
       "      <td>4.379545</td>\n",
       "      <td>4.241886</td>\n",
       "      <td>4.680351</td>\n",
       "      <td>4.780989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.207410</td>\n",
       "      <td>4.508425</td>\n",
       "      <td>4.100585</td>\n",
       "      <td>4.166837</td>\n",
       "      <td>4.530517</td>\n",
       "      <td>6.506971</td>\n",
       "      <td>4.483179</td>\n",
       "      <td>4.242860</td>\n",
       "      <td>5.138309</td>\n",
       "      <td>6.881151</td>\n",
       "      <td>...</td>\n",
       "      <td>4.371180</td>\n",
       "      <td>4.406084</td>\n",
       "      <td>4.186757</td>\n",
       "      <td>5.358646</td>\n",
       "      <td>4.632107</td>\n",
       "      <td>4.282658</td>\n",
       "      <td>4.237614</td>\n",
       "      <td>4.602680</td>\n",
       "      <td>4.637598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.245230</td>\n",
       "      <td>4.538779</td>\n",
       "      <td>4.040637</td>\n",
       "      <td>4.266853</td>\n",
       "      <td>4.326313</td>\n",
       "      <td>6.774611</td>\n",
       "      <td>4.409940</td>\n",
       "      <td>4.228860</td>\n",
       "      <td>4.948306</td>\n",
       "      <td>6.847382</td>\n",
       "      <td>...</td>\n",
       "      <td>4.345227</td>\n",
       "      <td>4.488653</td>\n",
       "      <td>4.364008</td>\n",
       "      <td>5.605900</td>\n",
       "      <td>4.624200</td>\n",
       "      <td>4.275774</td>\n",
       "      <td>4.251683</td>\n",
       "      <td>4.686359</td>\n",
       "      <td>4.687048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ILMN_1651217  ILMN_1651229  ILMN_1651234  ILMN_1651236  ILMN_1651237  \\\n",
       "0      4.229567      4.802085      4.145582      4.274502      4.268115   \n",
       "1      4.197183      4.820311      4.171221      4.332524      4.186809   \n",
       "2      4.131493      4.640774      4.075849      4.233316      4.334549   \n",
       "3      4.207410      4.508425      4.100585      4.166837      4.530517   \n",
       "4      4.245230      4.538779      4.040637      4.266853      4.326313   \n",
       "\n",
       "   ILMN_1651254  ILMN_1651259  ILMN_1651260  ILMN_1651261  ILMN_1651262  ...  \\\n",
       "0      6.853804      4.401350      4.123169      4.639975      7.136778  ...   \n",
       "1      6.663657      4.559615      4.278860      4.994493      6.803521  ...   \n",
       "2      6.694727      4.370504      4.169419      5.093272      6.720391  ...   \n",
       "3      6.506971      4.483179      4.242860      5.138309      6.881151  ...   \n",
       "4      6.774611      4.409940      4.228860      4.948306      6.847382  ...   \n",
       "\n",
       "   ILMN_1815885  ILMN_1815908  ILMN_1815923  ILMN_1815924  ILMN_1815933  \\\n",
       "0      4.376735      4.395501      4.338936      5.198647      4.594269   \n",
       "1      4.732124      4.417266      4.656831      4.615440      4.594269   \n",
       "2      4.292552      4.379864      4.211071      5.530672      4.570808   \n",
       "3      4.371180      4.406084      4.186757      5.358646      4.632107   \n",
       "4      4.345227      4.488653      4.364008      5.605900      4.624200   \n",
       "\n",
       "   ILMN_1815937  ILMN_1815938  ILMN_1815941  ILMN_1815951  CELIAC  \n",
       "0      4.264604      4.256310      4.821757      5.005588       1  \n",
       "1      4.336589      4.317376      4.518347      4.308311       1  \n",
       "2      4.379545      4.241886      4.680351      4.780989       1  \n",
       "3      4.282658      4.237614      4.602680      4.637598       1  \n",
       "4      4.275774      4.251683      4.686359      4.687048       1  \n",
       "\n",
       "[5 rows x 18982 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_samples.csv')\n",
    "df.drop(columns=['Unnamed: 0', 'name'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = list(df.columns[:-1])\n",
    "inputs = df[input_cols]\n",
    "target = df['CELIAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 10% best features (columns) based on ANOVA fit\n",
    "reduced_inputs = SelectPercentile().fit_transform(inputs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 1898)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1888</th>\n",
       "      <th>1889</th>\n",
       "      <th>1890</th>\n",
       "      <th>1891</th>\n",
       "      <th>1892</th>\n",
       "      <th>1893</th>\n",
       "      <th>1894</th>\n",
       "      <th>1895</th>\n",
       "      <th>1896</th>\n",
       "      <th>1897</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.275539</td>\n",
       "      <td>4.306251</td>\n",
       "      <td>4.618896</td>\n",
       "      <td>5.867003</td>\n",
       "      <td>6.521506</td>\n",
       "      <td>5.298801</td>\n",
       "      <td>5.940992</td>\n",
       "      <td>8.906818</td>\n",
       "      <td>4.752583</td>\n",
       "      <td>4.545288</td>\n",
       "      <td>...</td>\n",
       "      <td>4.205682</td>\n",
       "      <td>5.666388</td>\n",
       "      <td>5.706030</td>\n",
       "      <td>6.184561</td>\n",
       "      <td>5.777488</td>\n",
       "      <td>5.416096</td>\n",
       "      <td>4.431379</td>\n",
       "      <td>4.775627</td>\n",
       "      <td>5.408801</td>\n",
       "      <td>5.492253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.277917</td>\n",
       "      <td>4.210349</td>\n",
       "      <td>4.430293</td>\n",
       "      <td>6.353100</td>\n",
       "      <td>5.759897</td>\n",
       "      <td>5.670972</td>\n",
       "      <td>6.240782</td>\n",
       "      <td>9.213189</td>\n",
       "      <td>4.586740</td>\n",
       "      <td>4.307685</td>\n",
       "      <td>...</td>\n",
       "      <td>4.288189</td>\n",
       "      <td>5.344717</td>\n",
       "      <td>5.572897</td>\n",
       "      <td>6.347020</td>\n",
       "      <td>5.544384</td>\n",
       "      <td>5.666388</td>\n",
       "      <td>4.124898</td>\n",
       "      <td>4.249952</td>\n",
       "      <td>5.486251</td>\n",
       "      <td>5.244002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.215328</td>\n",
       "      <td>4.197578</td>\n",
       "      <td>4.707465</td>\n",
       "      <td>5.749865</td>\n",
       "      <td>5.771616</td>\n",
       "      <td>5.053427</td>\n",
       "      <td>5.306891</td>\n",
       "      <td>8.434439</td>\n",
       "      <td>4.709823</td>\n",
       "      <td>4.559511</td>\n",
       "      <td>...</td>\n",
       "      <td>4.193437</td>\n",
       "      <td>6.042542</td>\n",
       "      <td>5.353712</td>\n",
       "      <td>6.239423</td>\n",
       "      <td>6.421545</td>\n",
       "      <td>4.855159</td>\n",
       "      <td>4.540678</td>\n",
       "      <td>4.342777</td>\n",
       "      <td>5.279572</td>\n",
       "      <td>5.143543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.302285</td>\n",
       "      <td>4.279270</td>\n",
       "      <td>4.501162</td>\n",
       "      <td>5.544384</td>\n",
       "      <td>5.632207</td>\n",
       "      <td>4.922094</td>\n",
       "      <td>5.362721</td>\n",
       "      <td>8.479810</td>\n",
       "      <td>4.631826</td>\n",
       "      <td>4.613997</td>\n",
       "      <td>...</td>\n",
       "      <td>4.204624</td>\n",
       "      <td>6.099494</td>\n",
       "      <td>5.354935</td>\n",
       "      <td>6.127527</td>\n",
       "      <td>6.274439</td>\n",
       "      <td>5.072586</td>\n",
       "      <td>4.480567</td>\n",
       "      <td>4.334735</td>\n",
       "      <td>5.374753</td>\n",
       "      <td>5.241133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.302685</td>\n",
       "      <td>4.251547</td>\n",
       "      <td>4.683031</td>\n",
       "      <td>5.954345</td>\n",
       "      <td>5.754295</td>\n",
       "      <td>5.154511</td>\n",
       "      <td>5.450355</td>\n",
       "      <td>8.273638</td>\n",
       "      <td>4.790827</td>\n",
       "      <td>4.592735</td>\n",
       "      <td>...</td>\n",
       "      <td>4.080225</td>\n",
       "      <td>6.106028</td>\n",
       "      <td>5.635927</td>\n",
       "      <td>6.312757</td>\n",
       "      <td>6.326601</td>\n",
       "      <td>4.929269</td>\n",
       "      <td>4.611365</td>\n",
       "      <td>4.183861</td>\n",
       "      <td>5.151075</td>\n",
       "      <td>5.134198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1898 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  4.275539  4.306251  4.618896  5.867003  6.521506  5.298801  5.940992   \n",
       "1  4.277917  4.210349  4.430293  6.353100  5.759897  5.670972  6.240782   \n",
       "2  4.215328  4.197578  4.707465  5.749865  5.771616  5.053427  5.306891   \n",
       "3  4.302285  4.279270  4.501162  5.544384  5.632207  4.922094  5.362721   \n",
       "4  4.302685  4.251547  4.683031  5.954345  5.754295  5.154511  5.450355   \n",
       "\n",
       "       7         8         9     ...      1888      1889      1890      1891  \\\n",
       "0  8.906818  4.752583  4.545288  ...  4.205682  5.666388  5.706030  6.184561   \n",
       "1  9.213189  4.586740  4.307685  ...  4.288189  5.344717  5.572897  6.347020   \n",
       "2  8.434439  4.709823  4.559511  ...  4.193437  6.042542  5.353712  6.239423   \n",
       "3  8.479810  4.631826  4.613997  ...  4.204624  6.099494  5.354935  6.127527   \n",
       "4  8.273638  4.790827  4.592735  ...  4.080225  6.106028  5.635927  6.312757   \n",
       "\n",
       "       1892      1893      1894      1895      1896      1897  \n",
       "0  5.777488  5.416096  4.431379  4.775627  5.408801  5.492253  \n",
       "1  5.544384  5.666388  4.124898  4.249952  5.486251  5.244002  \n",
       "2  6.421545  4.855159  4.540678  4.342777  5.279572  5.143543  \n",
       "3  6.274439  5.072586  4.480567  4.334735  5.374753  5.241133  \n",
       "4  6.326601  4.929269  4.611365  4.183861  5.151075  5.134198  \n",
       "\n",
       "[5 rows x 1898 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df = pd.DataFrame(reduced_inputs)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_inputs, target, test_size=0.4, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 training examples\n",
      "14 validation examples\n",
      "39 test examples\n"
     ]
    }
   ],
   "source": [
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, stratify=Y_test)\n",
    "\n",
    "print(len(X_train), 'training examples')\n",
    "print(len(X_val), 'validation examples')\n",
    "print(len(X_test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.231, 4.218, 4.613, ..., 4.327, 5.44 , 5.165])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = np.array(X_train)\n",
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.array(Y_val)\n",
    "val_features = np.array(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(Y_test)\n",
    "test_features = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_input_cols = list(reduced_df.columns)\n",
    "for i in range(len(reduced_input_cols)):\n",
    "    reduced_input_cols[i] = str(reduced_input_cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [feature_column.numeric_column(c) for c in reduced_input_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='0', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='3', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='4', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "metrics = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='bin-accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will determine bias after training runs\n",
    "def make_model(output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    model = tf.keras.Sequential([\n",
    "#        feature_layer,\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation='sigmoid',\n",
    "                           bias_initializer=output_bias,\n",
    "                           name='output')\n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 5s 64ms/sample - loss: 0.4966 - tp: 59.0000 - fp: 11.0000 - tn: 2.0000 - fn: 7.0000 - bin-accuracy: 0.7722 - precision: 0.8429 - recall: 0.8939 - auc: 0.5023 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4781 - tp: 66.0000 - fp: 13.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - bin-accuracy: 0.8354 - precision: 0.8354 - recall: 1.0000 - auc: 0.4924 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4766 - tp: 66.0000 - fp: 13.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - bin-accuracy: 0.8354 - precision: 0.8354 - recall: 1.0000 - auc: 0.5385 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4778 - tp: 66.0000 - fp: 13.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - bin-accuracy: 0.8354 - precision: 0.8354 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4778 - tp: 66.0000 - fp: 13.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - bin-accuracy: 0.8354 - precision: 0.8354 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4804 - tp: 65.0000 - fp: 13.0000 - tn: 0.0000e+00 - fn: 1.0000 - bin-accuracy: 0.8228 - precision: 0.8333 - recall: 0.9848 - auc: 0.4924 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4700 - tp: 66.0000 - fp: 12.0000 - tn: 1.0000 - fn: 0.0000e+00 - bin-accuracy: 0.8481 - precision: 0.8462 - recall: 1.0000 - auc: 0.5385 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4778 - tp: 66.0000 - fp: 13.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - bin-accuracy: 0.8354 - precision: 0.8354 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4731 - tp: 66.0000 - fp: 12.0000 - tn: 1.0000 - fn: 0.0000e+00 - bin-accuracy: 0.8481 - precision: 0.8462 - recall: 1.0000 - auc: 0.5315 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4778 - tp: 66.0000 - fp: 13.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - bin-accuracy: 0.8354 - precision: 0.8354 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 11/100\n",
      " 8/79 [==>...........................] - ETA: 0s - loss: 0.5633 - tp: 6.0000 - fp: 2.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - bin-accuracy: 0.7500 - precision: 0.7500 - recall: 1.0000 - auc: 0.5000Restoring model weights from the end of the best epoch.\n",
      "79/79 [==============================] - 0s 1ms/sample - loss: 0.4778 - tp: 66.0000 - fp: 13.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - bin-accuracy: 0.8354 - precision: 0.8354 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.4561 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_bin-accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 00011: early stopping\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             multiple                  60768     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               multiple                  33        \n",
      "=================================================================\n",
      "Total params: 61,857\n",
      "Trainable params: 61,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.fit(train_features,\n",
    "          train_labels,\n",
    "          batch_size=8,\n",
    "          epochs=100,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(val_features, val_labels))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
